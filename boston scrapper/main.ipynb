{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb5a13a-71a9-4471-83cb-2b8c3cf34612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total URLs extracted: 500\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Load local XML file\n",
    "tree = ET.parse(\"sitemap.xml\")\n",
    "root = tree.getroot()\n",
    "\n",
    "# Extract all URLs\n",
    "urls = []\n",
    "for url in root.findall(\".//{http://www.sitemaps.org/schemas/sitemap/0.9}loc\"):\n",
    "    urls.append(url.text)\n",
    "\n",
    "print(f\"✅ Total URLs extracted: {len(urls)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd1381b-7e33-4545-a22a-eb2f35c59bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 500/500 [13:53<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done: 472 articles saved to scraped_data.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Change this if needed\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def extract_article_data(url):\n",
    "    try:\n",
    "        res = requests.get(url, headers=headers, timeout=10)\n",
    "        res.raise_for_status()\n",
    "        soup = BeautifulSoup(res.text, \"lxml\")\n",
    "\n",
    "        title = soup.find(\"title\").text.strip()\n",
    "        \n",
    "        # Try common content selectors — adapt as needed\n",
    "        article = soup.find(\"article\")\n",
    "        if article:\n",
    "            content = \" \".join(p.text for p in article.find_all(\"p\"))\n",
    "        else:\n",
    "            content = \" \".join(p.text for p in soup.find_all(\"p\"))\n",
    "\n",
    "        return {\n",
    "            \"url\": url,\n",
    "            \"title\": title,\n",
    "            \"content\": content.strip()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Load your extracted URLs here\n",
    "# urls = [...]  # You already have this from the XML\n",
    "scraped_data = []\n",
    "\n",
    "for url in tqdm(urls):\n",
    "    data = extract_article_data(url)\n",
    "    if data and data.get(\"content\"):\n",
    "        scraped_data.append(data)\n",
    "\n",
    "# ✅ Save to pickle file\n",
    "with open(\"scraped_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scraped_data, f)\n",
    "\n",
    "print(f\"✅ Done: {len(scraped_data)} articles saved to scraped_data.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4f8f8ac-68c5-4849-97e3-72d59357b8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 472 documents\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from llama_index.core import Document\n",
    "\n",
    "# Load data\n",
    "with open(\"scraped_data.pkl\", \"rb\") as f:\n",
    "    raw_data = pickle.load(f)\n",
    "\n",
    "# Convert to LlamaIndex Document objects\n",
    "documents = [\n",
    "    Document(\n",
    "        text=item[\"content\"],\n",
    "        metadata={\"title\": item[\"title\"], \"url\": item[\"url\"]}\n",
    "    )\n",
    "    for item in raw_data if item.get(\"content\")\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d30d45d-9c24-41de-95b1-15b2083854e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
